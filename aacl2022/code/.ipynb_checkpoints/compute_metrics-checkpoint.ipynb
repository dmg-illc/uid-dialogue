{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4913fd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "from torch.nn.functional import log_softmax\n",
    "from tqdm import tqdm\n",
    "from transformers import GPT2Tokenizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf849f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('chains_all.json', 'r') as f:\n",
    "    chains = json.load(f)\n",
    "len(chains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9956aa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    'surprisal_SBNC_gpt2_50_1e-3_agg.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecb1c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue_ids = set(df['Dialogue ID'].tolist())\n",
    "print('{} dialogues'.format(len(dialogue_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3402fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcde38f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_subsequence(subsequence, sequence):\n",
    "    l = len(subsequence)\n",
    "    ranges = []\n",
    "    for i in range(len(sequence)):\n",
    "        if sequence[i:i+l] == subsequence:\n",
    "            ranges.append((i, i+l))\n",
    "    return ranges\n",
    "\n",
    "def find_subsequence_plain_text(subsequence, sequence):\n",
    "    try:\n",
    "        l = len(subsequence)\n",
    "    except TypeError:\n",
    "        print(subsequence)\n",
    "    ranges = []\n",
    "    for i in range(len(sequence)):\n",
    "        if sequence[i:i+l] == subsequence:\n",
    "            if i - 1 < 0:\n",
    "                space_before = True\n",
    "            else:\n",
    "                space_before = sequence[i-1] in \" ',.!:;?\"\n",
    "  \n",
    "            if i + l >= len(sequence):\n",
    "                space_after = True\n",
    "            else:\n",
    "                space_after = sequence[i+l] in \" ',.!:;?\"\n",
    "                \n",
    "            if space_before and space_after:\n",
    "                ranges.append((i, i+l))\n",
    "    return ranges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cfa7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def facilitating_effect(turn_surprisal_values, construction_indices, window=10):\n",
    "    start_constr, end_constr = construction_indices\n",
    "    \n",
    "    if window:\n",
    "        start_ctx = start_constr - window\n",
    "        if start_ctx < 0:\n",
    "            start_ctx = 0\n",
    "        end_ctx = end_constr + window\n",
    "        if end_ctx > len(turn_surprisal_values):\n",
    "            end_ctx = len(turn_surprisal_values)\n",
    "    else:\n",
    "        start_ctx = 0\n",
    "        end_ctx = len(turn_surprisal_values)\n",
    "        \n",
    "    indices_locus = [i for i in range(start_ctx, end_ctx) if i not in range(start_constr, end_constr)]\n",
    "    \n",
    "    if not indices_locus:\n",
    "        return 0\n",
    "    \n",
    "    surprisal_wo_constr = np.mean(\n",
    "        [h for i, h in enumerate(turn_surprisal_values) if i in indices_locus]\n",
    "    )\n",
    "    surprisal_constr = np.mean(\n",
    "        [h for i, h in enumerate(turn_surprisal_values) if i in range(start_constr, end_constr)]\n",
    "    )\n",
    "    \n",
    "    return np.log2(surprisal_wo_constr / surprisal_constr)\n",
    "\n",
    "\n",
    "def std_surprisal(turn_surprisal_values, construction_indices, window=None):\n",
    "    start_constr, end_constr = construction_indices\n",
    "    surprisal_constr = np.mean(\n",
    "        [h for i, h in enumerate(turn_surprisal_values) if i in range(start_constr, end_constr)]\n",
    "    )\n",
    "    if window:\n",
    "        start_ctx = start_constr - window\n",
    "        if start_ctx < 0:\n",
    "            start_ctx = 0\n",
    "        end_ctx = end_constr + window\n",
    "        if end_ctx > len(turn_surprisal_values):\n",
    "            end_ctx = len(turn_surprisal_values)\n",
    "    else:\n",
    "        start_ctx = 0\n",
    "        end_ctx = len(turn_surprisal_values)\n",
    "        \n",
    "    mu = np.mean(turn_surprisal_values[start_ctx: end_ctx])\n",
    "    sigma = np.std(turn_surprisal_values[start_ctx: end_ctx])\n",
    "    \n",
    "    return (surprisal_constr - mu) / sigma\n",
    "\n",
    "\n",
    "def surprisal(turn_surprisal_values, construction_indices):\n",
    "    start_constr, end_constr = construction_indices\n",
    "    surprisal_constr = np.mean(\n",
    "        [h for i, h in enumerate(turn_surprisal_values) if i in range(start_constr, end_constr)]\n",
    "    )\n",
    "    return surprisal_constr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e6378e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_chains = {}\n",
    "\n",
    "constrs = Counter()\n",
    "\n",
    "for d_id in tqdm(chains):\n",
    "        \n",
    "    new_chains[d_id] = {}\n",
    "    \n",
    "    df_d = df[df['Dialogue ID'] == d_id]\n",
    "    for constr in chains[d_id]:\n",
    "        \n",
    "        new_chains[d_id][constr] = []\n",
    "    \n",
    "        constr_tokens_w_space = tokenizer.convert_ids_to_tokens(tokenizer(' ' + constr)['input_ids'])\n",
    "        constr_tokens_wo_space = tokenizer.convert_ids_to_tokens(tokenizer(constr)['input_ids'])\n",
    "        \n",
    "        prev_turn = None\n",
    "        for occurrence in chains[d_id][constr]:\n",
    "\n",
    "            df_row = df_d[df_d['Turn index'] == int(occurrence['CurrentTurn'])]\n",
    "            \n",
    "            turn_tokens = df_row['Tokens'].to_list()\n",
    "            if not turn_tokens:\n",
    "                print(d_id, constr)\n",
    "                print('skip')\n",
    "                continue\n",
    "            \n",
    "            if not occurrence['Topical']:\n",
    "                constrs[constr] += 1\n",
    "            \n",
    "            turn_tokens = eval(turn_tokens[0])\n",
    "                \n",
    "#             turn_string = tokenizer.convert_tokens_to_string(turn_tokens)\n",
    "            \n",
    "            ranges1 = find_subsequence(constr_tokens_w_space, turn_tokens)\n",
    "            ranges2 = find_subsequence(constr_tokens_wo_space, turn_tokens)\n",
    "            ranges = ranges1 + ranges2\n",
    "            ranges.sort(key=lambda x:x[0])\n",
    "            \n",
    "            if len(ranges) > occurrence['FrequencyInTurn']:\n",
    "                # Remove extra ranges due to LM tokenizer's splitting differently:\n",
    "                # \"it was er\" found in \"it was erm\" because tokenizer splits \"erm\" into (\"er\", \"m\")\n",
    "                new_ranges = []\n",
    "                for r in ranges:\n",
    "                    extended_span = turn_tokens[r[0]-1: r[1]+1]\n",
    "                    extended_span_plain = tokenizer.convert_tokens_to_string(extended_span)\n",
    "                    if find_subsequence_plain_text(constr, extended_span_plain):\n",
    "                        new_ranges.append(r)\n",
    "                ranges = new_ranges\n",
    "                \n",
    "            elif len(ranges) < occurrence['FrequencyInTurn']:\n",
    "                # Occcurs only once: construction is at too high position in the sentence.\n",
    "                # Sentences are truncated after 1024 tokens during surprisal estimation.\n",
    "                new_chains[d_id][constr].append(\n",
    "                    {**occurrence, **{\n",
    "                        'FE': float('NaN'),\n",
    "                        'FE1': float('NaN'),\n",
    "                        'FE2': float('NaN'),\n",
    "                        'FE3': float('NaN'),\n",
    "                        'FE4': float('NaN'),\n",
    "                        'FE5': float('NaN'),\n",
    "                        'FE10': float('NaN'),\n",
    "                        'FE15': float('NaN'),\n",
    "                        'FE20': float('NaN'),\n",
    "                        'FE25': float('NaN'),\n",
    "                        'FE30': float('NaN'),\n",
    "                        'SS': float('NaN'),\n",
    "                        'S' : float('NaN')\n",
    "                    }}\n",
    "                )\n",
    "                continue\n",
    "                \n",
    "            start_idx, end_idx = ranges[occurrence['IndexInTurn']]\n",
    "            \n",
    "            tok_surprisal = eval(df_row['Surprisal'].to_list()[0])\n",
    "            assert len(tok_surprisal) == len(turn_tokens)\n",
    "\n",
    "            fe = facilitating_effect(tok_surprisal, (start_idx, end_idx), window=None)\n",
    "            fe1 = facilitating_effect(tok_surprisal, (start_idx, end_idx), window=1)\n",
    "            fe2 = facilitating_effect(tok_surprisal, (start_idx, end_idx), window=2)\n",
    "            fe3 = facilitating_effect(tok_surprisal, (start_idx, end_idx), window=3)\n",
    "            fe4 = facilitating_effect(tok_surprisal, (start_idx, end_idx), window=4)\n",
    "            fe5 = facilitating_effect(tok_surprisal, (start_idx, end_idx), window=5)\n",
    "            fe10 = facilitating_effect(tok_surprisal, (start_idx, end_idx), window=10)\n",
    "            fe15 = facilitating_effect(tok_surprisal, (start_idx, end_idx), window=15)\n",
    "            fe20 = facilitating_effect(tok_surprisal, (start_idx, end_idx), window=20)\n",
    "            fe25 = facilitating_effect(tok_surprisal, (start_idx, end_idx), window=25)\n",
    "            fe30 = facilitating_effect(tok_surprisal, (start_idx, end_idx), window=30)\n",
    "    \n",
    "#             if fe10 > 10:\n",
    "#                 print(constr)\n",
    "#                 print(turn_tokens[st: en])\n",
    "#                 print(tok_surprisal[st: en])\n",
    "#                 print(tok_surprisal[start_idx: end_idx])\n",
    "#                 print()\n",
    "    \n",
    "            ss = std_surprisal(tok_surprisal, (start_idx, end_idx))\n",
    "            s = surprisal(tok_surprisal, (start_idx, end_idx))\n",
    "            \n",
    "            new_chains[d_id][constr].append(\n",
    "                {**occurrence, **{\n",
    "                    'FE': fe,\n",
    "                    'FE1': fe1,\n",
    "                    'FE2': fe2,\n",
    "                    'FE3': fe3,\n",
    "                    'FE4': fe4,\n",
    "                    'FE5': fe5,\n",
    "                    'FE10': fe10,\n",
    "                    'FE15': fe15,\n",
    "                    'FE20': fe20,\n",
    "                    'FE25': fe25,\n",
    "                    'FE30': fe30,\n",
    "                    'SS': ss,\n",
    "                    'S' : s,\n",
    "                }}\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d41e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(constrs.values()), len(constrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9048ac88",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd80a825",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = []\n",
    "for d_id in new_chains:\n",
    "    for constr in new_chains[d_id]:\n",
    "        for occurrence in new_chains[d_id][constr]:\n",
    "            df_data.append((d_id, constr,) + tuple(occurrence.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba8fbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(new_chains['SD8N'][\"it's like a\"][0].keys())\n",
    "columns = ['Dialogue ID', 'Form'] + columns\n",
    "\n",
    "df = pd.DataFrame(df_data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceb2ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6486166",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('chains_all_SBNC_gpt2_50_1e-3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f702f956",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
