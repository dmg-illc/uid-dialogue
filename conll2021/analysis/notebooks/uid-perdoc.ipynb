{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff92841-b3e5-4a4c-bb1a-5dd780460dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import trange, tqdm\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (6,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a050c808-43d6-48ef-b1b2-9eff70ba84d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptb = pd.read_csv('../results_conll/mi/ptb_gpt2-ft.csv').dropna()\n",
    "pb = pd.read_csv('../results_conll/mi/pb_gpt2-ft.csv').dropna()\n",
    "bncs = pd.read_csv('../results_conll/mi/bnc_spoken_gpt2-ft.csv').dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9205f583-deb6-4f13-b18b-c60895719f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptb['position'] = ptb['position_in_doc']\n",
    "pb['position'] = pb['position_in_dialogue']\n",
    "\n",
    "ptb['path'] = ptb['doc_id']\n",
    "pb['path'] = pb['dialogue_id']\n",
    "bncs['path'] = bncs['dialogue_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da93ec0b-9121-4f1c-9d4a-82d5d78b0e47",
   "metadata": {},
   "source": [
    "# Global centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07affa3e-e3c9-47c4-80ac-1ce30e59bcd7",
   "metadata": {},
   "source": [
    "## Using average estimates per position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5963a296-bb4d-4871-81f5-c2c02dd39bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_centrality(df, estimate='normalised_h_doc', ctx_name='path', shuffle=False):\n",
    "    centralities = []\n",
    "    for doc_id in set(df[ctx_name].values):\n",
    "        doc_h_estimates = df[df[ctx_name] == doc_id][estimate].values\n",
    "        if shuffle:\n",
    "            doc_h_estimates = np.random.permutation(doc_h_estimates)\n",
    "        var = np.mean(abs(doc_h_estimates - doc_h_estimates.mean()) ** 2)\n",
    "        centralities.append(var)\n",
    "    return - np.array(centralities)\n",
    "\n",
    "def normalised_global_centrality(df, estimate='normalised_h_doc', ctx_name='path', shuffle=False):\n",
    "    centralities = []\n",
    "    for doc_id in set(df[ctx_name].values):\n",
    "        doc_h_estimates = df[df[ctx_name] == doc_id][estimate].values\n",
    "        if shuffle:\n",
    "            doc_h_estimates = np.random.permutation(doc_h_estimates)\n",
    "        var = np.mean(abs(doc_h_estimates / np.mean(doc_h_estimates) - 1) ** 2)\n",
    "        centralities.append(var)\n",
    "    return - np.array(centralities)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3776f77e-fec5-4653-a28d-c5be71c5dd06",
   "metadata": {},
   "source": [
    "# Local predictability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941b5da2-a3c1-4fe4-a167-b70ff5a48b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_predictability(df, estimate='normalised_h_doc', ctx_name='path', shuffle=False):\n",
    "    centralities = []\n",
    "    for doc_id in set(df[ctx_name].values):\n",
    "        doc_h_estimates = df[df[ctx_name] == doc_id][estimate].values\n",
    "        if shuffle:\n",
    "            doc_h_estimates = np.random.permutation(doc_h_estimates)\n",
    "        sum_squared_diffs = 0\n",
    "        for i in range(1, len(doc_h_estimates)):\n",
    "            sum_squared_diffs += abs(doc_h_estimates[i] - doc_h_estimates[i - 1]) ** 2\n",
    "        var = sum_squared_diffs / len(doc_h_estimates)\n",
    "        centralities.append(var)\n",
    "    return - np.array(centralities)\n",
    "\n",
    "\n",
    "def normalised_local_predictability(df, estimate='normalised_h_doc', ctx_name='path', shuffle=False):\n",
    "    centralities = []\n",
    "    for doc_id in set(df[ctx_name].values):\n",
    "        doc_h_estimates = df[df[ctx_name] == doc_id][estimate].values\n",
    "        if shuffle:\n",
    "            doc_h_estimates = np.random.permutation(doc_h_estimates)\n",
    "        doc_h_mean = np.mean(doc_h_estimates)\n",
    "        sum_squared_diffs = 0\n",
    "        for i in range(1, len(doc_h_estimates)):\n",
    "            sum_squared_diffs += abs(doc_h_estimates[i] - doc_h_estimates[i - 1]) ** 2\n",
    "        normalised_sum = sum_squared_diffs / (doc_h_mean ** 2)\n",
    "        var = normalised_sum / len(doc_h_estimates)\n",
    "        centralities.append(var)\n",
    "    return - np.array(centralities)\n",
    "\n",
    "\n",
    "def locally_normalised_local_predictability(df, estimate='normalised_h_doc', ctx_name='path', shuffle=False):\n",
    "    centralities = []\n",
    "    for doc_id in set(df[ctx_name].values):\n",
    "        doc_h_estimates = df[df[ctx_name] == doc_id][estimate].values \n",
    "        if shuffle:\n",
    "            doc_h_estimates = np.random.permutation(doc_h_estimates)\n",
    "        sum_squared_diffs = 0\n",
    "        for i in range(1, len(doc_h_estimates)):\n",
    "            sum_squared_diffs += abs(doc_h_estimates[i] / doc_h_estimates[i - 1] - 1) ** 2\n",
    "        var = sum_squared_diffs / len(doc_h_estimates)\n",
    "        centralities.append(var)\n",
    "    return - np.array(centralities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16b50a0-a9d6-440b-822b-c6f847b11dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['Local predictability', 'Global centrality']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bd716a-34e5-49a9-a101-0461140966cb",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8d82ba-6f82-42de-982c-101dccb58091",
   "metadata": {},
   "source": [
    "# All corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c343e6b-67b5-4cdb-86de-6257daafb724",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "uid_list = []\n",
    "\n",
    "for corpus, corpus_name in [(ptb, 'Penn Treebank'), (pb, 'PhotoBook'), (bncs, 'Spoken BNC')]:\n",
    "#     , (fiction, 'Fiction'), (news, 'News'), (acad, 'Academic'), (nonac, 'Non-academic'), (unpub, 'Unpublished'), (other, 'Other pubs')]:\n",
    "\n",
    "#     corpus = corpus[corpus['position'] > 5]\n",
    "    corpus = corpus[corpus['length'] > 0]\n",
    "    \n",
    "    for x in global_centrality(corpus, 'normalised_h_doc'):\n",
    "        uid_list.append((corpus_name, 'Global centrality', x))\n",
    "        \n",
    "#     for x in normalised_global_centrality(corpus):\n",
    "#         uid_list.append((corpus_name, 'Normalised global centrality', x))\n",
    "        \n",
    "    for x in local_predictability(corpus, 'normalised_h_doc'):\n",
    "        uid_list.append((corpus_name, 'Local predictability', x))\n",
    "        \n",
    "#     for x in normalised_local_predictability(corpus):\n",
    "#         uid_list.append((corpus_name, 'Normalised local predictability', x))\n",
    "        \n",
    "#     for x in locally_normalised_local_predictability(corpus):\n",
    "#         uid_list.append((corpus_name, 'Locally normalised local predictability', x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34564eb-11fe-4417-98b8-5642ad8fec7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flat = pd.DataFrame(uid_list, columns=['corpus', 'Uniformity metric', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cb40a8-1d19-4688-8fb4-165d8e0ad640",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in ['Global centrality']:\n",
    "#     sns.set_style(\"whitegrid\")\n",
    "#     sns.set_palette(sns.color_palette(colors))\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    ax = sns.barplot(x='corpus', y='score',\n",
    "                     data=df_flat[df_flat['Uniformity metric']==metric], color=\"teal\")\n",
    "    sns.despine(left=True)\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('$\\leftarrow$ {}'.format(metric))\n",
    "    sns.set(font_scale = 1.5)\n",
    "    ax.invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "#     plt.show()\n",
    "    plt.savefig('/Users/mario/code/erp-paper/conll2021/figures/wlimit/glob-cent.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ef44b2-b754-4b75-bcac-1dca919cc756",
   "metadata": {},
   "source": [
    "# All corpora shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937c1558-88ec-4af4-b2f5-170227f2e5f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [np.random.randint(100000) for _ in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d933d85-3199-4ec8-9e99-a9404240e49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_dfs = []\n",
    "for seed in tqdm(seeds):\n",
    "    uid_list_random = []\n",
    "\n",
    "    for corpus, corpus_name in [(ptb, 'Penn Treebank'), (pb, 'PhotoBook'), (bncs, 'Spoken BNC')]:\n",
    "#         (fiction, 'Fiction'), (news, 'News'), (acad, 'Academic'), (nonac, 'Non-academic'), (unpub, 'Unpublished'), (other, 'Other pubs')]:\n",
    "        \n",
    "        corpus = corpus[corpus['length'] > 0]\n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        for x in global_centrality(corpus, 'normalised_h_doc', shuffle=True):\n",
    "            uid_list_random.append((corpus_name, 'Global centrality', x))\n",
    "\n",
    "#         for x in normalised_global_centrality(corpus, 'normalised_h', shuffle=True):\n",
    "#             uid_list_random.append((corpus_name, 'Normalised global centrality', x))\n",
    "\n",
    "        for x in local_predictability(corpus,'normalised_h_doc', shuffle=True):\n",
    "            uid_list_random.append((corpus_name, 'Local predictability', x))\n",
    "\n",
    "#         for x in normalised_local_predictability(corpus, 'normalised_h', shuffle=True):\n",
    "#             uid_list_random.append((corpus_name, 'Normalised local predictability', x))\n",
    "\n",
    "#         for x in locally_normalised_local_predictability(corpus, 'normalised_h', shuffle=True):\n",
    "#             uid_list_random.append((corpus_name, 'Locally normalised local predictability', x))\n",
    "\n",
    "    random_dfs.append(\n",
    "        pd.DataFrame(uid_list_random, columns=['corpus', 'Uniformity metric', '_score'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd2de21-54ae-4898-a453-31dc2e0d4518",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([d['_score'] for d in random_dfs], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c5a4f7-5ce0-47f7-ac47-a5dc66df841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat['corpus'] = random_dfs[0]['corpus'].values\n",
    "df_concat['Uniformity metric'] = random_dfs[0]['Uniformity metric'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7931743-5ed8-4a86-8351-9fd410d3ab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat['score'] = df_concat['_score'].mean(axis=1).values\n",
    "df_concat.drop(columns=['_score'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3731b26e-94c1-43eb-89cb-f24a5bd61646",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flat['Order'] = 'True'\n",
    "df_flat.head()\n",
    "\n",
    "df_concat['Order'] = \"Control\"\n",
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafeefa6-b883-4bee-aa6c-13a26372d0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat((df_flat, df_concat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fc1e83-8842-413a-9c78-365cb6912e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for metric in ['Local predictability']:\n",
    "    \n",
    "sns.set_style(\"whitegrid\")\n",
    "colors = [\"teal\", \"lightsteelblue\"]\n",
    "\n",
    "sns.set_palette(sns.color_palette(colors))\n",
    "\n",
    "ax = sns.barplot(x='corpus', y='score', hue='Order',\n",
    "                 data=final_df[final_df['Uniformity metric'] == 'Local predictability'])\n",
    "sns.despine(left=True)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('$\\leftarrow$ {}'.format('Local predictability'))\n",
    "sns.set(font_scale = 1.5)\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "plt.savefig('/Users/mario/code/erp-paper/conll2021/figures/wlimit/loc-pred.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297977f7-0d17-4cda-9005-3439e44cb8cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
